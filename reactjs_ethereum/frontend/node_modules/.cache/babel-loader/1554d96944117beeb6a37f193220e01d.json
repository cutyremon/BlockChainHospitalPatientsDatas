{"ast":null,"code":"'use strict';\n\nvar _classCallCheck = require(\"/home/cutyremon/blockChain/reactjs_ethereum/frontend/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"/home/cutyremon/blockChain/reactjs_ethereum/frontend/node_modules/@babel/runtime/helpers/createClass\");\n\nvar each = require('async/each');\n\nvar queue = require('async/queue');\n\nvar WorkerQueue =\n/*#__PURE__*/\nfunction () {\n  /**\n   * Creates a new WorkerQueue.\n   *\n   * @param {DHT} dht\n   * @param {Run} run\n   * @param {Object} path\n   * @param {function} log\n   */\n  function WorkerQueue(dht, run, path, log) {\n    _classCallCheck(this, WorkerQueue);\n\n    this.dht = dht;\n    this.run = run;\n    this.path = path;\n    this.log = log;\n    this.concurrency = this.dht.concurrency;\n    this.queue = this.setupQueue();\n  }\n  /**\n   * Create the underlying async queue.\n   *\n   * @returns {Object}\n   */\n\n\n  _createClass(WorkerQueue, [{\n    key: \"setupQueue\",\n    value: function setupQueue() {\n      var _this = this;\n\n      var q = queue(this.processNext.bind(this), this.concurrency); // If there's an error, stop the worker\n\n      q.error = function (err) {\n        _this.log.error('queue', err);\n\n        _this.stop(err);\n      }; // When all peers in the queue have been processed, stop the worker\n\n\n      q.drain = function () {\n        _this.log('queue:drain');\n\n        _this.stop();\n      }; // When a space opens up in the queue, add some more peers\n\n\n      q.unsaturated = function () {\n        if (_this.running) {\n          _this.fill();\n        }\n      };\n\n      q.buffer = 0;\n      return q;\n    }\n    /**\n     * Stop the worker, optionally providing an error to pass to the worker's\n     * callback.\n     *\n     * @param {Error} err\n     */\n\n  }, {\n    key: \"stop\",\n    value: function stop(err) {\n      if (!this.running) {\n        return;\n      }\n\n      this.running = false;\n      this.queue.kill();\n      this.log('worker:stop, %d workers still running', this.run.workers.filter(function (w) {\n        return w.running;\n      }).length);\n      this.callbackFn(err);\n    }\n    /**\n     * Use the queue from async to keep `concurrency` amount items running\n     * per path.\n     *\n     * @param {function(Error)} callback\n     */\n\n  }, {\n    key: \"execute\",\n    value: function execute(callback) {\n      this.running = true;\n      this.callbackFn = callback;\n      this.fill();\n    }\n    /**\n     * Add peers to the worker queue until there are enough to satisfy the\n     * worker queue concurrency.\n     * Note that we don't want to take any more than those required to satisfy\n     * concurrency from the peers-to-query queue, because we always want to\n     * query the closest peers to the key first, and new peers are continously\n     * being added to the peers-to-query queue.\n     */\n\n  }, {\n    key: \"fill\",\n    value: function fill() {\n      // Note:\n      // - queue.running(): number of items that are currently running\n      // - queue.length(): the number of items that are waiting to be run\n      while (this.queue.running() + this.queue.length() < this.concurrency && this.path.peersToQuery.length > 0) {\n        this.queue.push(this.path.peersToQuery.dequeue());\n      }\n    }\n    /**\n     * Process the next peer in the queue\n     *\n     * @param {PeerId} peer\n     * @param {function(Error)} cb\n     * @returns {void}\n     */\n\n  }, {\n    key: \"processNext\",\n    value: function processNext(peer, cb) {\n      var _this2 = this;\n\n      if (!this.running) {\n        return cb();\n      } // The paths must be disjoint, meaning that no two paths in the Query may\n      // traverse the same peer\n\n\n      if (this.run.peersSeen.has(peer)) {\n        return cb();\n      } // Check if we've queried enough peers already\n\n\n      this.run.continueQuerying(this, function (err, continueQuerying) {\n        if (!_this2.running) {\n          return cb();\n        }\n\n        if (err) {\n          return cb(err);\n        } // No peer we're querying is closer stop the queue\n        // This will cause queries that may potentially result in\n        // closer nodes to be ended, but it reduces overall query time\n\n\n        if (!continueQuerying) {\n          _this2.stop();\n\n          return cb();\n        } // Check if another path has queried this peer in the mean time\n\n\n        if (_this2.run.peersSeen.has(peer)) {\n          return cb();\n        }\n\n        _this2.run.peersSeen.add(peer); // Execute the query on the next peer\n\n\n        _this2.log('queue:work');\n\n        _this2.execQuery(peer, function (err, state) {\n          // Ignore response after worker killed\n          if (!_this2.running) {\n            return cb();\n          }\n\n          _this2.log('queue:work:done', err, state);\n\n          if (err) {\n            return cb(err);\n          } // If query is complete, stop all workers.\n          // Note: run.stop() calls stop() on all the workers, which kills the\n          // queue and calls callbackFn()\n\n\n          if (state && state.queryComplete) {\n            _this2.log('query:complete');\n\n            _this2.run.stop();\n\n            return cb();\n          } // If path is complete, just stop this worker.\n          // Note: this.stop() kills the queue and calls callbackFn()\n\n\n          if (state && state.pathComplete) {\n            _this2.stop();\n\n            return cb();\n          } // Otherwise, process next peer\n\n\n          cb();\n        });\n      });\n    }\n    /**\n     * Execute a query on the next peer.\n     *\n     * @param {PeerId} peer\n     * @param {function(Error)} callback\n     * @returns {void}\n     * @private\n     */\n\n  }, {\n    key: \"execQuery\",\n    value: function execQuery(peer, callback) {\n      var _this3 = this;\n\n      this.path.queryFunc(peer, function (err, res) {\n        // If the run has completed, bail out\n        if (!_this3.running) {\n          return callback();\n        }\n\n        if (err) {\n          _this3.run.errors.push(err);\n\n          return callback();\n        } // Add the peer to the closest peers we have successfully queried\n\n\n        _this3.run.peersQueried.add(peer, function (err) {\n          if (err) {\n            return callback(err);\n          } // If the query indicates that this path or the whole query is complete\n          // set the path result and bail out\n\n\n          if (res.pathComplete || res.queryComplete) {\n            _this3.path.res = res;\n            return callback(null, {\n              pathComplete: res.pathComplete,\n              queryComplete: res.queryComplete\n            });\n          } // If there are closer peers to query, add them to the queue\n\n\n          if (res.closerPeers && res.closerPeers.length > 0) {\n            return each(res.closerPeers, function (closer, cb) {\n              // don't add ourselves\n              if (_this3.dht._isSelf(closer.id)) {\n                return cb();\n              }\n\n              closer = _this3.dht.peerBook.put(closer);\n\n              _this3.dht._peerDiscovered(closer);\n\n              _this3.path.addPeerToQuery(closer.id, cb);\n            }, callback);\n          }\n\n          callback();\n        });\n      });\n    }\n  }]);\n\n  return WorkerQueue;\n}();\n\nmodule.exports = WorkerQueue;","map":null,"metadata":{},"sourceType":"script"}